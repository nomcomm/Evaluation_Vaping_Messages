library(emmeans)
library(readr)
#set directory and load file
setwd("/Users/suelim/Documents/Research/DONE/Evaluation_Vaping_Messages/github/Evaluation_Vaping_Messages/data/02_Data/study2")
df_total <- read_csv('02_cleaned_data_file/study2_data_file.csv')
#demographics
table(df_total$Experimental_Group)
mean(df_total$Age, na.rm=TRUE)
sd(df_total$Age, na.rm=TRUE)
table(df_total$Sex) / length(df_total$Sex)
df_total_prolific <-
df_total  %>% filter(df_total$recruitment_platform == "Prolific")
mean(df_total_prolific$Age, na.rm=TRUE)
sd(df_total_prolific$Age, na.rm=TRUE)
table(df_total_prolific$Sex) / length(df_total_prolific$Sex)
df_total_sona <-
df_total  %>% filter(df_total$recruitment_platform == "SONA")
mean(df_total_sona$Age, na.rm=TRUE)
sd(df_total_sona$Age, na.rm=TRUE)
table(df_total_sona$Sex) / length(df_total_sona$Sex)
#creating Effects Perception (EP) and Perception of AI variables
sum_AI_EP <- 0
sum_Human_EP <- 0
for (i in 1:15) {
df_total[[paste0("AI", i, "_EP")]] <-
(df_total[[paste0("Dis_AI", i)]] + df_total[[paste0("Con_AI", i)]] +
df_total[[paste0("Unp_AI", i)]]) / 3
sum_AI_EP <- sum_AI_EP + df_total[[paste0("AI", i, "_EP")]]
}
df_total$AI_mean_EP <- sum_AI_EP / 15
for (i in 1:15) {
df_total[[paste0("Human", i, "_EP")]] <-
(df_total[[paste0("Dis_Hum", i)]] + df_total[[paste0("Con_Hum", i)]] +
df_total[[paste0("Unp_Hum", i)]]) / 3
sum_Human_EP <- sum_Human_EP + df_total[[paste0("Human", i, "_EP")]]
}
df_total$Human_mean_EP <- sum_Human_EP / 15
df_total$AIper_neg <-
(df_total$Per_AI3_1 + df_total$Per_AI6_1 + df_total$Per_AI8_1 + df_total$Per_AI9_1 +
df_total$Per_AI10_1 + df_total$Per_AI15_1 + df_total$Per_AI19_1 + df_total$Per_AI20_1)/8
AI_Message_Count <-
df_total[, c("Message1", "Message2", "Message3", "Message4", "Message5")] <= 15
df_total$AI_Message_Count <- rowSums(AI_Message_Count)
df_total <- df_total |> relocate(AI_Message_Count, .after = Message5)
#cronbach alpha
alpha_values <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai <- df_total[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum <- df_total[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values[i] <- alpha(subset_ai)$total$raw_alpha
alpha_values[i + 15] <- alpha(subset_hum)$total$raw_alpha
}
print(alpha_values)
mean(alpha_values)
df_new <- data.frame(
Per_AI3_1 = df_total$Per_AI3_1,
Per_AI6_1 = df_total$Per_AI6_1,
Per_AI8_1 = df_total$Per_AI8_1,
Per_AI9_1 = df_total$Per_AI9_1,
Per_AI10_1 = df_total$Per_AI10_1,
Per_AI15_1 = df_total$Per_AI15_1,
Per_AI19_1 = df_total$Per_AI19_1,
Per_AI20_1 = df_total$Per_AI20_1
)
alpha <- alpha(df_new)$total$raw_alpha
mean(df_total$AIper_neg, na.rm=TRUE)
sd(df_total$AIper_neg, na.rm=TRUE)
hist(df_total$AIper_neg)
# Restructing data structure
df_total_3EPs <- df_total[c(1:2, 123:137, 139:153, 155)]
df_total_3EPs_pivot <- df_total_3EPs |>
pivot_longer(!c(Experimental_Group, Participant, AIper_neg), names_to="Messages",
values_to="Effects_Perception") |>
mutate(AI_or_Hum = ifelse(grepl("^AI", Messages), "AI", "Human"))
df_total_3EPs_pivot$Participant <- factor(df_total_3EPs_pivot$Participant)
df_total_3EPs_pivot$Experimental_Group <- factor(df_total_3EPs_pivot$Experimental_Group)
df_total_3EPs_pivot$AI_or_Hum <- as.factor(df_total_3EPs_pivot$AI_or_Hum)
df_total_3EPs_pivot$Experimental_Group <- relevel(df_total_3EPs_pivot$Experimental_Group, ref = "Not Disclosed")
df_total_3EPs_pivot$AI_or_Hum <- relevel(df_total_3EPs_pivot$AI_or_Hum, ref = "AI")
df_total_3EPs_pivot$Messages <- factor(df_total_3EPs_pivot$Messages)
df_total_3EPs_pivot %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
#mixed effects modeling
total_EP3_ANOVA <-
lmer(Effects_Perception ~ Experimental_Group * AI_or_Hum * AIper_neg + (1 | Participant) + (1 | Messages), data = df_total_3EPs_pivot)
summary(total_EP3_ANOVA)
anova(total_EP3_ANOVA, type="3")
library(tidyr)
library(ggplot2)
library(dplyr)
library(rstatix)
library(WebPower)
library(readr)
library(lmerTest)
library(lme4)
library(ordinal)
#power analysis for mixed ANOVA
wp.rmanova(ng = 2, nm = 3, f = 0.25, nscor = 1, alpha = 0.05, power = .8, type = 2)
#set directory and load file
setwd("/Users/suelim/Documents/Research/DONE/Evaluation_Vaping_Messages/github/Evaluation_Vaping_Messages/data/02_Data/study1/02_cleaned_data_file")
df_total <- read_csv('study1_data_file.csv')
#demographics
table(df_total$Experimental_Group)
mean(df_total$Age, na.rm=TRUE)
sd(df_total$Age, na.rm=TRUE)
table(df_total$Sex) / length(df_total$Sex)
#creating Effects Perception (EP) and Ranking variables
sum_AI_EP <- 0
sum_Human_EP <- 0
for (i in 1:15) {
df_total[[paste0("AI", i, "_EP")]] <-
(df_total[[paste0("Dis_AI", i)]] + df_total[[paste0("Con_AI", i)]] +
df_total[[paste0("Unp_AI", i)]]) / 3
sum_AI_EP <- sum_AI_EP + df_total[[paste0("AI", i, "_EP")]]
}
df_total$AI_mean_EP <- sum_AI_EP / 15
for (i in 1:15) {
df_total[[paste0("Human", i, "_EP")]] <-
(df_total[[paste0("Dis_Hum", i)]] + df_total[[paste0("Con_Hum", i)]] +
df_total[[paste0("Unp_Hum", i)]]) / 3
sum_Human_EP <- sum_Human_EP + df_total[[paste0("Human", i, "_EP")]]
}
df_total$Human_mean_EP <- sum_Human_EP / 15
sum_Rank_AI <- 0
sum_Rank_Human <- 0
for (i in 1:15) {
sum_Rank_AI <- sum_Rank_AI + df_total[[paste0("Rank_AI", i)]]
}
df_total$AI_MSG_Rank_mean <- sum_Rank_AI / 15
for (i in 1:15) {
sum_Rank_Human <- sum_Rank_Human + df_total[[paste0("Rank_Human", i)]]
}
df_total$Hum_MSG_Rank_mean <- sum_Rank_Human / 15
#cronbach alpha reliability calculations
alpha_values <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai <- df_total[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum <- df_total[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values[i] <- alpha(subset_ai)$total$raw_alpha
alpha_values[i + 15] <- alpha(subset_hum)$total$raw_alpha
}
print(alpha_values)
mean(alpha_values)
# Mixed ANOVA
df_total_AI_3EPs <- df_total[c(1:2, 156:170, 172:186)]
df_total_AI_3EPs_pivot <- df_total_AI_3EPs |>
pivot_longer(!c(Experimental_Group, Participant), names_to="Messages",
values_to="Effects_Perception") |>
mutate(AI_or_Hum = ifelse(grepl("^AI", Messages), "AI", "Human"))
df_total_AI_3EPs_pivot$AI_or_Hum <- as.factor(df_total_AI_3EPs_pivot$AI_or_Hum)
df_total_AI_3EPs_pivot$AI_or_Hum <- relevel(df_total_AI_3EPs_pivot$AI_or_Hum, ref = "AI")
df_total_AI_3EPs_pivot$Participant <- as.factor(df_total_AI_3EPs_pivot$Participant)
df_total_AI_3EPs_pivot$Experimental_Group <- as.factor(df_total_AI_3EPs_pivot$Experimental_Group)
df_total_AI_3EPs_pivot$Experimental_Group <- relevel(df_total_AI_3EPs_pivot$Experimental_Group, ref = "Not Disclosed")
df_total_AI_3EPs_pivot$Messages <- as.factor(df_total_AI_3EPs_pivot$Messages)
df_total_AI_3EPs_pivot %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
#EP_Mixed_Effects <-
EP_Mixed_Effects <-
lmer(Effects_Perception ~ Experimental_Group * AI_or_Hum + (1 | Participant) + (1 | Messages), data = df_total_AI_3EPs_pivot)
Anova(EP_Mixed_Effects, type="3")
EP_predict <-
emmeans(EP_Mixed_Effects, ~ Experimental_Group * AI_or_Hum)
EP_predict_df <- as.data.frame(EP_predict)
ggplot(EP_predict_df, aes(x = Experimental_Group, y = emmean)) +
geom_line(aes(group = AI_or_Hum), position = position_dodge(0.3), color="dimgray") +
geom_point(aes(color = AI_or_Hum), position = position_dodge(0.3), size=3) +
geom_errorbar(
aes(ymin = asymp.LCL, ymax = asymp.UCL, color = AI_or_Hum),
width = 0.2,
position = position_dodge(0.3)
) +
theme(plot.title = element_text(hjust = 0.5)) +
#facet_wrap(~Experimental_Group) +
labs(
y = "Effects Perception",
x = NULL,
color = "Message Source"  # This line changes the legend title
) +
theme_bw() +
scale_color_manual(values = c("AI" = "steelblue", "Human" = "darkgreen")) +
ylim(3.9, 4.6)
library(tidyr)
library(ggplot2)
library(dplyr)
library(rstatix)
library(WebPower)
library(readr)
library(lmerTest)
library(lme4)
library(ordinal)
library(emmeans)
library(psych)
#set directory and load file
setwd("/Users/suelim/Documents/Research/DONE/Evaluation_Vaping_Messages/github/Evaluation_Vaping_Messages/data/02_Data/study1/02_cleaned_data_file")
df_total <- read_csv('study1_data_file.csv')
#creating Effects Perception (EP) and Ranking variables
sum_AI_EP <- 0
sum_Human_EP <- 0
for (i in 1:15) {
df_total[[paste0("AI", i, "_EP")]] <-
(df_total[[paste0("Dis_AI", i)]] + df_total[[paste0("Con_AI", i)]] +
df_total[[paste0("Unp_AI", i)]]) / 3
sum_AI_EP <- sum_AI_EP + df_total[[paste0("AI", i, "_EP")]]
}
df_total$AI_mean_EP <- sum_AI_EP / 15
for (i in 1:15) {
df_total[[paste0("Human", i, "_EP")]] <-
(df_total[[paste0("Dis_Hum", i)]] + df_total[[paste0("Con_Hum", i)]] +
df_total[[paste0("Unp_Hum", i)]]) / 3
sum_Human_EP <- sum_Human_EP + df_total[[paste0("Human", i, "_EP")]]
}
df_total$Human_mean_EP <- sum_Human_EP / 15
sum_Rank_AI <- 0
sum_Rank_Human <- 0
for (i in 1:15) {
sum_Rank_AI <- sum_Rank_AI + df_total[[paste0("Rank_AI", i)]]
}
df_total$AI_MSG_Rank_mean <- sum_Rank_AI / 15
for (i in 1:15) {
sum_Rank_Human <- sum_Rank_Human + df_total[[paste0("Rank_Human", i)]]
}
df_total$Hum_MSG_Rank_mean <- sum_Rank_Human / 15
colnames(df_total)
#demographics, separated by sample
df_total_prolific <-
df_total  %>% filter(df_total$recruitment_platform == "Prolific")
table(df_total_prolific$Experimental_Group)
mean(df_total_prolific$Age, na.rm=TRUE)
sd(df_total_prolific$Age, na.rm=TRUE)
table(df_total_prolific$Sex) / length(df_total_prolific$Sex)
df_total_sona <-
df_total  %>% filter(df_total$recruitment_platform == "SONA")
table(df_total_sona$Experimental_Group)
mean(df_total_sona$Age, na.rm=TRUE)
sd(df_total_sona$Age, na.rm=TRUE)
table(df_total_sona$Sex) / length(df_total_sona$Sex)
#cronbach alpha reliability calculations
alpha_values_prolific <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai_pro <- df_total_prolific[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum_pro <- df_total_prolific[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values_prolific[i] <- alpha(subset_ai_pro)$total$raw_alpha
alpha_values_prolific[i + 15] <- alpha(subset_hum_pro)$total$raw_alpha
}
print(alpha_values_prolific)
mean(alpha_values_prolific)
alpha_values_sona <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai_sona <- df_total_sona[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum_sona <- df_total_sona[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values_sona[i] <- alpha(subset_ai_sona)$total$raw_alpha
alpha_values_sona[i + 15] <- alpha(subset_hum_sona)$total$raw_alpha
}
print(alpha_values_sona)
mean(alpha_values_sona)
# Preparing data structure for mixed-effects modeling
df_total_AI_3EPs <- df_total[c(1:2, 155:170, 172:186)]
df_total_AI_3EPs_pivot <- df_total_AI_3EPs |>
pivot_longer(!c(Experimental_Group, Participant, recruitment_platform), names_to="Messages",
values_to="Effects_Perception") |>
mutate(AI_or_Hum = ifelse(grepl("^AI", Messages), "AI", "Human"))
df_total_AI_3EPs_pivot$AI_or_Hum <- as.factor(df_total_AI_3EPs_pivot$AI_or_Hum)
df_total_AI_3EPs_pivot$AI_or_Hum <- relevel(df_total_AI_3EPs_pivot$AI_or_Hum, ref = "AI")
df_total_AI_3EPs_pivot$Participant <- as.factor(df_total_AI_3EPs_pivot$Participant)
df_total_AI_3EPs_pivot$Experimental_Group <- as.factor(df_total_AI_3EPs_pivot$Experimental_Group)
df_total_AI_3EPs_pivot$Experimental_Group <- relevel(df_total_AI_3EPs_pivot$Experimental_Group, ref = "Not Disclosed")
df_total_AI_3EPs_pivot$Messages <- as.factor(df_total_AI_3EPs_pivot$Messages)
df_total_AI_3EPs_pivot$recruitment_platform <- as.factor(df_total_AI_3EPs_pivot$recruitment_platform)
#Prolific sample
df_total_AI_3EPs_pivot_prolific <-
df_total_AI_3EPs_pivot %>%
filter(df_total_AI_3EPs_pivot$recruitment_platform == "Prolific")
##means and standard deviations of EP and ranking
df_total_AI_3EPs_pivot_prolific %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_AI_3EPs_pivot_prolific %>%
get_summary_stats(Effects_Perception, type = "full")
##mixed effects modeling
EP_Mixed_Effects_prolific <-
lmer(Effects_Perception ~ Experimental_Group * AI_or_Hum + (1 | Participant) + (1 | Messages), data = df_total_AI_3EPs_pivot_prolific)
summary(EP_Mixed_Effects_prolific)
##mixed effects modeling
EP_Mixed_Effects_prolific <-
lmer(Effects_Perception ~ Experimental_Group * AI_or_Hum + (1 | Participant) + (1 | Messages), data = df_total_AI_3EPs_pivot_prolific)
summary(EP_Mixed_Effects_prolific)
EP_predict_prolific <-
emmeans(EP_Mixed_Effects_prolific, ~ Experimental_Group * AI_or_Hum)
EP_predict_prolific_df <- as.data.frame(EP_predict_prolific)
ggplot(EP_predict_prolific_df, aes(x = AI_or_Hum, y = emmean)) +
geom_line(aes(group = Experimental_Group), position = position_dodge(0.9), color="dimgray") +
geom_point(aes(color = AI_or_Hum), position = position_dodge(0.9), size=3) +
geom_errorbar(
aes(ymin = lower.CL, ymax = upper.CL, color = AI_or_Hum),
width = 0.2,
position = position_dodge(0.9)
) +
theme(plot.title = element_text(hjust = 0.5)) +
facet_wrap(~Experimental_Group) +
labs(y = "Effects Perception",
x = NULL) +
theme_bw() +
scale_color_manual(values = c("AI" = "steelblue", "Human" = "darkgreen")) +
theme(legend.position = "none") +   ylim(3,5)
#Prolific sample
df_total_AI_3EPs_pivot_prolific <-
df_total_AI_3EPs_pivot %>%
filter(df_total_AI_3EPs_pivot$recruitment_platform == "Prolific")
##means and standard deviations of EP and ranking
df_total_AI_3EPs_pivot_prolific %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_AI_3EPs_pivot_prolific %>%
get_summary_stats(Effects_Perception, type = "full")
4.19-.045
4.19+.045
#SONA sample
df_total_AI_3EPs_pivot_sona <-
df_total_AI_3EPs_pivot %>%
filter(df_total_AI_3EPs_pivot$recruitment_platform == "SONA")
##means and standard deviations of EP and ranking
df_total_AI_3EPs_pivot_sona %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_AI_3EPs_pivot_sona %>%
get_summary_stats(Effects_Perception, type = "full")
4.26-.031
4.26+.031
library(tidyr)
library(ggplot2)
library(dplyr)
library(rstatix)
library(lmerTest)
library(lme4)
library(emmeans)
library(readr)
#set directory and load file
setwd("/Users/suelim/Documents/Research/DONE/Evaluation_Vaping_Messages/github/Evaluation_Vaping_Messages/data/02_Data/study2")
df_total <- read_csv('02_cleaned_data_file/study2_data_file.csv')
#demographics
df_total_prolific <-
df_total  %>% filter(df_total$recruitment_platform == "Prolific")
table(df_total_prolific$Experimental_Group)
mean(df_total_prolific$Age, na.rm=TRUE)
sd(df_total_prolific$Age, na.rm=TRUE)
table(df_total_prolific$Sex) / length(df_total_prolific$Sex)
df_total_sona <-
df_total  %>% filter(df_total$recruitment_platform == "SONA")
table(df_total_sona$Experimental_Group)
mean(df_total_sona$Age, na.rm=TRUE)
sd(df_total_sona$Age, na.rm=TRUE)
table(df_total_sona$Sex) / length(df_total_sona$Sex)
#creating Effects Perception (EP) and Perception of AI variables
sum_AI_EP <- 0
sum_Human_EP <- 0
for (i in 1:15) {
df_total[[paste0("AI", i, "_EP")]] <-
(df_total[[paste0("Dis_AI", i)]] + df_total[[paste0("Con_AI", i)]] +
df_total[[paste0("Unp_AI", i)]]) / 3
sum_AI_EP <- sum_AI_EP + df_total[[paste0("AI", i, "_EP")]]
}
df_total$AI_mean_EP <- sum_AI_EP / 15
for (i in 1:15) {
df_total[[paste0("Human", i, "_EP")]] <-
(df_total[[paste0("Dis_Hum", i)]] + df_total[[paste0("Con_Hum", i)]] +
df_total[[paste0("Unp_Hum", i)]]) / 3
sum_Human_EP <- sum_Human_EP + df_total[[paste0("Human", i, "_EP")]]
}
df_total$Human_mean_EP <- sum_Human_EP / 15
df_total$AIper_neg <-
(df_total$Per_AI3_1 + df_total$Per_AI6_1 + df_total$Per_AI8_1 + df_total$Per_AI9_1 +
df_total$Per_AI10_1 + df_total$Per_AI15_1 + df_total$Per_AI19_1 + df_total$Per_AI20_1)/8
AI_Message_Count <-
df_total[, c("Message1", "Message2", "Message3", "Message4", "Message5")] <= 15
df_total$AI_Message_Count <- rowSums(AI_Message_Count)
df_total <- df_total |> relocate(AI_Message_Count, .after = Message5)
colnames(df_total)
#demographics
df_total_prolific <-
df_total  %>% filter(df_total$recruitment_platform == "Prolific")
table(df_total_prolific$Experimental_Group)
mean(df_total_prolific$Age, na.rm=TRUE)
sd(df_total_prolific$Age, na.rm=TRUE)
table(df_total_prolific$Sex) / length(df_total_prolific$Sex)
mean(df_total_prolific$AIper_neg, na.rm=TRUE)
sd(df_total_prolific$AIper_neg, na.rm=TRUE)
df_total_sona <-
df_total  %>% filter(df_total$recruitment_platform == "SONA")
table(df_total_sona$Experimental_Group)
mean(df_total_sona$Age, na.rm=TRUE)
sd(df_total_sona$Age, na.rm=TRUE)
table(df_total_sona$Sex) / length(df_total_sona$Sex)
mean(df_total_sona$AIper_neg, na.rm=TRUE)
sd(df_total_sona$AIper_neg, na.rm=TRUE)
#cronbach alpha
alpha_values_prolific <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai_pro <- df_total_prolific[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum_pro <- df_total_prolific[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values_prolific[i] <- alpha(subset_ai_pro)$total$raw_alpha
alpha_values_prolific[i + 15] <- alpha(subset_hum_pro)$total$raw_alpha
}
print(alpha_values_prolific)
mean(alpha_values_prolific)
alpha_values_sona <- numeric(30)
for (i in 1:15) {
# Create a subset for each message (AI and Human)
subset_ai_sona <- df_total_sona[, c(paste("Dis_AI", i, sep=""), paste("Con_AI", i, sep=""), paste("Unp_AI", i, sep=""))]
subset_hum_sona <- df_total_sona[, c(paste("Dis_Hum", i, sep=""), paste("Con_Hum", i, sep=""), paste("Unp_Hum", i, sep=""))]
# Calculate and store Cronbach's alpha for each message
alpha_values_sona[i] <- alpha(subset_ai_sona)$total$raw_alpha
alpha_values_sona[i + 15] <- alpha(subset_hum_sona)$total$raw_alpha
}
print(alpha_values_sona)
mean(alpha_values_sona)
df_new_prolific <- data.frame(
Per_AI3_1 = df_total_prolific$Per_AI3_1,
Per_AI6_1 = df_total_prolific$Per_AI6_1,
Per_AI8_1 = df_total_prolific$Per_AI8_1,
Per_AI9_1 = df_total_prolific$Per_AI9_1,
Per_AI10_1 = df_total_prolific$Per_AI10_1,
Per_AI15_1 = df_total_prolific$Per_AI15_1,
Per_AI19_1 = df_total_prolific$Per_AI19_1,
Per_AI20_1 = df_total_prolific$Per_AI20_1
)
df_new_sona <- data.frame(
Per_AI3_1 = df_total_sona$Per_AI3_1,
Per_AI6_1 = df_total_sona$Per_AI6_1,
Per_AI8_1 = df_total_sona$Per_AI8_1,
Per_AI9_1 = df_total_sona$Per_AI9_1,
Per_AI10_1 = df_total_sona$Per_AI10_1,
Per_AI15_1 = df_total_sona$Per_AI15_1,
Per_AI19_1 = df_total_sona$Per_AI19_1,
Per_AI20_1 = df_total_sona$Per_AI20_1
)
alpha_prolific <- alpha(df_new_prolific)$total$raw_alpha
alpha_sona <- alpha(df_new_sona)$total$raw_alpha
# Preparing data structure for mixed-effects modeling
df_total_3EPs <- df_total[c(1:2, 122:137, 139:153, 155)]
df_total_3EPs_pivot <- df_total_3EPs |>
pivot_longer(!c(Experimental_Group, Participant, AIper_neg, recruitment_platform), names_to="Messages",
values_to="Effects_Perception") |>
mutate(AI_or_Hum = ifelse(grepl("^AI", Messages), "AI", "Human"))
df_total_3EPs_pivot$Participant <- factor(df_total_3EPs_pivot$Participant)
df_total_3EPs_pivot$Experimental_Group <- factor(df_total_3EPs_pivot$Experimental_Group)
df_total_3EPs_pivot$AI_or_Hum <- factor(df_total_3EPs_pivot$AI_or_Hum)
df_total_3EPs_pivot$Experimental_Group <- relevel(df_total_3EPs_pivot$Experimental_Group, ref = "Not Disclosed")
df_total_3EPs_pivot$AI_or_Hum <- relevel(df_total_3EPs_pivot$AI_or_Hum, ref = "AI")
df_total_3EPs_pivot$Messages <- factor(df_total_3EPs_pivot$Messages)
total_EP3_ANOVA <-
lmer(Effects_Perception ~ Experimental_Group * AI_or_Hum*AIper_neg + (1 | Participant) + (1 | Messages), data = df_total_3EPs_pivot)
summary(total_EP3_ANOVA)
predict_mean <-
emmeans(total_EP3_ANOVA, ~ Experimental_Group * AI_or_Hum * AIper_neg, at = list(AIper_neg = c(1, 2, 3, 4, 5)))
predict_mean_df <- as.data.frame(predict_mean)
ggplot(predict_mean_df, aes(x = AIper_neg, y = emmean, color = AI_or_Hum)) +
geom_line(size = 1.25) +
facet_wrap(~Experimental_Group) +
labs(x = "Mean Negative Attitudes Towards AI", y = "Effects Perception", color = "Message Source") +
theme_bw() +
scale_colour_manual(values = c("AI" = "steelblue", "Human" = "darkgreen")) +
ylim(1,5)
#Prolific sample
df_total_3EPs_pivot_prolific <-
df_total_3EPs_pivot |>
filter(df_total_3EPs_pivot$recruitment_platform == "Prolific")
##means and standard deviations of EP and ranking
df_total_3EPs_pivot_prolific %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_3EPs_pivot_prolific %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_3EPs_pivot_prolific %>%
get_summary_stats(Effects_Perception, type = "full")
3.91-.037
3.91+.037
#SONA sample
df_total_3EPs_pivot_sona <-
df_total_3EPs_pivot |>
filter(df_total_3EPs_pivot$recruitment_platform == "SONA")
##means and standard deviations of EP and ranking
df_total_3EPs_pivot_sona %>%
group_by(Experimental_Group, AI_or_Hum) %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
df_total_3EPs_pivot_sona %>%
get_summary_stats(Effects_Perception, type = "mean_sd")
4.23-.835
df_total_3EPs_pivot_sona %>%
get_summary_stats(Effects_Perception, type = "full")
4.23-.037
4.23+.037
df_total_3EPs_pivot_prolific %>%
get_summary_stats(AIper_neg, type = "full")
2.94-.027
2.94+.027
df_total_3EPs_pivot_sona %>%
get_summary_stats(AIper_neg, type = "full")
3.22-.032
3.22+.032
